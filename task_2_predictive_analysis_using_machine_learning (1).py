# -*- coding: utf-8 -*-
"""Task_2_Predictive Analysis using Machine Learning.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1-lE5i-a1BSeRGSNnhAI7IH74hxzR2nbe
"""

!pip install -q pandas scikit-learn matplotlib seaborn

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt

from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score

df = pd.read_csv("/content/Walmart_Sales.csv")
df.head()

# Check for missing values
print("Missing values:\n", df.isnull().sum())

# Drop or fill missing values
df = df.dropna()

# a target variable 'High_Sales'
# Define high sales as sales greater than or equal to mean sales
threshold = df['Weekly_Sales'].mean()
df['High_Sales'] = df['Weekly_Sales'].apply(lambda x: 1 if x >= threshold else 0)

# Drop unnecessary columns
# Drop 'Date', 'Weekly_Sales' to prevent data leakage
features = df.drop(columns=['Weekly_Sales', 'High_Sales', 'Date'], errors='ignore')
target = df['High_Sales']

# Train-test split
X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)

# Feature Scaling
from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

#Train Logistic Regression
model = LogisticRegression()
model.fit(X_train_scaled, y_train)

# Evaluate model
y_pred = model.predict(X_test_scaled)

print("âœ… Accuracy:", accuracy_score(y_test, y_pred))
print("\nClassification Report:\n", classification_report(y_test, y_pred))

# Confusion Matrix
cm = confusion_matrix(y_test, y_pred)
sns.heatmap(cm, annot=True, fmt='d', cmap='Purples', xticklabels=['Low', 'High'], yticklabels=['Low', 'High'])
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.title("Confusion Matrix")
plt.show()

# Predict on new data (example row from dataset)
sample = features.sample(1)
sample_scaled = scaler.transform(sample)
prediction = model.predict(sample_scaled)
print(f"Sample Input:\n{sample}")
print("Prediction: ", "High Sales" if prediction[0] == 1 else "Low Sales")

# Distribution of Weekly Sales
plt.figure(figsize=(10, 6))
sns.histplot(df['Weekly_Sales'], bins=30, kde=True, color='skyblue')
plt.axvline(threshold, color='red', linestyle='--', label=f"Mean = {threshold:.2f}")
plt.title("Distribution of Weekly Sales")
plt.xlabel("Weekly Sales")
plt.ylabel("Frequency")
plt.legend()
plt.show()

# Correlation Heatmap
plt.figure(figsize=(12, 8))
correlation = df.corr(numeric_only=True)
sns.heatmap(correlation, annot=True, cmap='coolwarm', fmt=".2f")
plt.title("Correlation Heatmap of Numeric Features")
plt.show()

# Average Weekly Sales by Store (Top 10)
top_stores = df.groupby("Store")['Weekly_Sales'].mean().sort_values(ascending=False).head(10)

plt.figure(figsize=(10, 6))
sns.barplot(x=top_stores.index, y=top_stores.values, palette='viridis')
plt.title("Top 10 Stores by Average Weekly Sales")
plt.xlabel("Store Number")
plt.ylabel("Average Weekly Sales")
plt.show()